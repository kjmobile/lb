{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kjmobile/lb/blob/main/14_Neural_Network_3_Q.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqxnslml3tu6"
   },
   "source": [
    "# Neural Net 3 - common techniques in neural net modeling  \n",
    "- validation loss, drop out, save and load model, and call back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M54mUYlhwnex"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGP-X65EmJBg"
   },
   "source": [
    "## Loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZsGl9udlqZk"
   },
   "outputs": [],
   "source": [
    "#Import dataset, normalize the train set, and set aside validtaion set\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(train_input, train_target), (test_input, test_target) = \\\n",
    "    keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "train_scaled = train_input / 255.0\n",
    "\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "    train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iogH7o0Ll6uL"
   },
   "outputs": [],
   "source": [
    "# In this example, we create a simple function that consolidates the model design process, we've used in previous examples.\n",
    "# if block indicats that if, and only if, a_layer is passesed as an argument, we add the layer before the output layer.\n",
    "def model_fn(a_layer=None):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "    model.add(keras.layers.Dense(100, activation='relu'))\n",
    "    if a_layer:\n",
    "        model.add(a_layer)\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Eh6hM4DNdzu",
    "outputId": "e346acc8-1bfc-4c99-adea-fd4081a95f6a"
   },
   "outputs": [],
   "source": [
    "model = model_fn()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-UK21N_mCM0",
    "outputId": "95fc1ce0-5fca-4c87-d999-dfa6794ded84"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_scaled, train_target, epochs=5, verbose=1)\n",
    "\n",
    "#In addition to the model fitting sequences, model.fit() also returns an History object as <keras.src.callbacks.History at 0x7e7540258160>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmJQ_zoH2ct_"
   },
   "outputs": [],
   "source": [
    "# save the returned object as history\n",
    "history = model.fit(train_scaled, train_target, epochs=5, verbose=0)\n",
    "# vervbose =0 suppresses printing the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vwo-oAgO4QKQ",
    "outputId": "6d804fef-1b71-42f9-cc3b-0973b81a2ddf"
   },
   "outputs": [],
   "source": [
    "# # we can find the loss and accuracy history in the form of a dictionary\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "uz_TCdfPmG6e",
    "outputId": "646f6dc8-dd27-4d23-bda5-05cc7059a758"
   },
   "outputs": [],
   "source": [
    "# plot loss history : note that the nerual net optimizes for 'loss'  not 'accuracy'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "CpmK9lXQcBe9",
    "outputId": "84c29f15-1aa5-464a-e12e-0d8dc4fb1d01"
   },
   "outputs": [],
   "source": [
    "#plot epoch history\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cJlWITXqJWr"
   },
   "outputs": [],
   "source": [
    "# increase the epochs to 20\n",
    "model_1 = model_fn()\n",
    "model_1.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "history_1 = model_1.fit(train_scaled, train_target, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "YT87Fjo2qKPC",
    "outputId": "c88bf5a5-7e85-4abd-cb6f-394a52b7b43a"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_1.history['loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGqf6ceRr3zO"
   },
   "source": [
    "## validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_iHvMxwu2D2",
    "outputId": "da385c9d-4dcc-4ca3-d55e-af81dcc5c91d"
   },
   "outputs": [],
   "source": [
    "model_2 = model_fn()\n",
    "model_2.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "history_2 = model_2.fit(train_scaled, train_target, epochs=20, verbose=1,\n",
    "                        validation_data=(val_scaled, val_target))\n",
    "# To compute the validation score, validation_data parameter is added in fit() function ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJ5RGEmLu5KI",
    "outputId": "2add25ce-ffd4-4ae3-814e-e6b59e321bae"
   },
   "outputs": [],
   "source": [
    "print(history_2.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAhLDhDYFdVg"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LY1TwtnAFD9O",
    "outputId": "938e7c13-61db-4a3b-e664-5719c566a9c7"
   },
   "outputs": [],
   "source": [
    "min(history_2.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "zcpm7CpXu5vC",
    "outputId": "7151f8e8-7320-440c-b598-07851e29cf74"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_2.history['loss'])\n",
    "plt.plot(history_2.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train loss ', 'val loss'])\n",
    "plt.show()\n",
    "\n",
    "# while train loss continue to decrease, the validation loss stop decreasing after 0.35 level, leading to an over fitting.\n",
    "# As one of the ways to prevent the overfit, we may change the default optimizer(RMSprop) to Adam optimizer, which uses adaptive learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qC8gDwo3qcJv"
   },
   "outputs": [],
   "source": [
    "# let's compile the same model but replacing the default optimizer(RMSprop) with 'adam'\n",
    "model_3 = model_fn()\n",
    "model_3.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "              metrics='accuracy')\n",
    "\n",
    "history_3 = model_3.fit(train_scaled, train_target, epochs=20, verbose=0,\n",
    "                    validation_data=(val_scaled, val_target))\n",
    "# Now, the val_loss goes down  (lower than the model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrSEgUEvErgq",
    "outputId": "afa5b802-c990-47f8-f709-a082d28c66c6"
   },
   "outputs": [],
   "source": [
    "min(history_3.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "k8wWnyFzsLKb",
    "outputId": "5499fa05-770a-44aa-d6bb-d97318a94bd3"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_3.history['loss'])\n",
    "plt.plot(history_3.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-dFY8lrYXm3"
   },
   "source": [
    "## Dropout (J. Hinton 2017)\n",
    "- One of the regularization techniques that work well in neural net\n",
    "- By randomly dropping neurons, dropout forces the model to become more robust, as it cannot rely on the presence of any specific neuron\n",
    "- By randomly dropping neurons, each training step uses a different subset of neurons, akin to training a different model (aka, ensemble effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AppFtFKgsk--",
    "outputId": "d18a011a-e947-4743-ef2d-804c0c55188f"
   },
   "outputs": [],
   "source": [
    "# Now we add anothe layer (a dropout layer) to the prevous model\n",
    "# The default is 0.5 (i.e., randomly dropping out 50% of the nodes)\n",
    "model_4 = model_fn(keras.layers.Dropout(0.3))\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_TSe7oM9v1lW",
    "outputId": "ee4a27cb-48cf-474d-fa93-8d361609b332"
   },
   "outputs": [],
   "source": [
    "#\n",
    "model_4.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "history_4 = model_4.fit(train_scaled, train_target, epochs=20, verbose=1,\n",
    "                    validation_data=(val_scaled, val_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oti8iNGUKYKo",
    "outputId": "8037f3ff-b632-4c0a-c760-c610734e5e2d"
   },
   "outputs": [],
   "source": [
    "min(history_4.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_O-fHcYNGG4U",
    "outputId": "4c3d7df0-7641-4e88-c51e-2fca8c5bfb16"
   },
   "outputs": [],
   "source": [
    "np.argmin(history_4.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "Rj_syB_iv30l",
    "outputId": "18e0700e-88c9-48cb-f758-2395586117f9"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_4.history['loss'])\n",
    "plt.plot(history_4.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()\n",
    "# Now the val_loss continues to go down to 0.317(lower than Model_3's 0.318), overfit has been substantially decreased.\n",
    "# The model perfomance was at its best at 18th epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQi91PCQorHr"
   },
   "source": [
    "## Saving and loading the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npsYdX3rv6Oa"
   },
   "outputs": [],
   "source": [
    "# fix the epoch to 13 and rerun the model\n",
    "model_5 = model_fn(keras.layers.Dropout(0.3))\n",
    "model_5.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "              metrics='accuracy')\n",
    "\n",
    "history_5 = model_5.fit(train_scaled, train_target, epochs=18, verbose=0,\n",
    "                    validation_data=(val_scaled, val_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OcByWFVCE2wk",
    "outputId": "0df160d5-3891-4593-cfe2-917cb22875a3"
   },
   "outputs": [],
   "source": [
    "model_5.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hWVYzt0Y2FPm"
   },
   "outputs": [],
   "source": [
    "model_5.save_weights('model_5_weights.h5') # h5 is an extension for HDF5 format(Hierarchical Data Format version 5; goog for saving large hierachical dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NissHzcq3xbN"
   },
   "outputs": [],
   "source": [
    "model_5.save('model_5_whole.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vljkGGu3AUl"
   },
   "outputs": [],
   "source": [
    "#!ls -al *.h5  # a linux command to : 'list (ls) all, detailed(-al) everthing (*) witht the extention .h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-t6gC5Z3GCM"
   },
   "outputs": [],
   "source": [
    "# Loading the saved model_5 as a new model_6\n",
    "model_6 = model_fn(keras.layers.Dropout(0.3))\n",
    "model_6.load_weights('model_5_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34ZC0te8au3G"
   },
   "outputs": [],
   "source": [
    "#alternatively we can simply load the model as a new model_7\n",
    "model_7 =keras.models.load_model('model_5_whole.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pHV9tBnzi8St",
    "outputId": "c23c51bc-594f-4a56-86d8-47f4fa37e5b9"
   },
   "outputs": [],
   "source": [
    "# model 6 and 7 shows the same accuracies\n",
    "# Note that in keras, predict() returns all probabilties for all 10 classes, unlike sklearn.\n",
    "# So we need to select index of the maximum predicted values out of these 10 per each sample.\n",
    "# axis =-1, let np.argmax select the max along the last dimension of the returned array\n",
    "# Those selected labels should be compared to target values to compute the mean(i.e., accuracies)\n",
    "import numpy as np\n",
    "\n",
    "val_labels = np.argmax(model_6.predict(val_scaled), axis=-1)\n",
    "print(np.mean(val_labels == val_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFsp9HkrbWVg",
    "outputId": "b542c18c-9cbc-476b-a990-31c129795a9e"
   },
   "outputs": [],
   "source": [
    "val_labels = np.argmax(model_7.predict(val_scaled), axis=-1)\n",
    "print(np.mean(val_labels == val_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SHvmQYf2cSDR",
    "outputId": "3e2d42eb-ebb2-4295-bf76-209c201d311a"
   },
   "outputs": [],
   "source": [
    "# When the entire model is saved and reloaded, we can get the accuracy by simply using evaluate() method\n",
    "model_7.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sRM3Vpki4QyH"
   },
   "outputs": [],
   "source": [
    "# However evaluate() function will not work for model_6 since it only contains the wieghts and did not compiled the model itself.\n",
    "# model_6.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NTCF3YD3EyA"
   },
   "source": [
    "## Call back\n",
    "- In the above approach, we run the model_4 first finding out the epoch 13 was the best, and then we run the model_5 with the epochs = 13 parameter.\n",
    "- We can do this without runing the model twice by using a parameter, callbacks =  ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L2lKN_934VB4",
    "outputId": "e9d3d429-bcb4-4c6d-949d-a5c3dcabdb1a"
   },
   "outputs": [],
   "source": [
    "model_8 = model_fn(keras.layers.Dropout(0.3))\n",
    "model_8.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-model.h5',monitor ='val_loss', save_best_only=True)# 'val_loss' is the default for monitor\n",
    "\n",
    "model_8.fit(train_scaled, train_target, epochs=20, verbose=1,\n",
    "          validation_data=(val_scaled, val_target),\n",
    "          callbacks=[checkpoint_cb])\n",
    "# \"callbacks\" refer to the Functions that are automatically executed at specific points during the training process\n",
    "# checkpoint will be created only when the 'val_loss' is improved than the previous epochs\n",
    "# callbacks applied by passing checkpoint_cv wrapped in a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYISeH6U5oh9",
    "outputId": "ab9cb881-cc28-4d43-d7ba-8172233b5ac7"
   },
   "outputs": [],
   "source": [
    "#best-model is saved from the above; now load the best model and evaluate.\n",
    "model_9 = keras.models.load_model('best-model.h5')\n",
    "model_9.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oScRnVVC3RLv"
   },
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3jEt51m23he"
   },
   "source": [
    "- Above, we noted that the best-model was found AFTER completing all 20 epoches\n",
    "- We can reduce it by adding EarlyStopping that specifies a pacience level for when there is no improvement\n",
    "- Early stopping can be considered one of regularization methods as it prevents over fitting too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLLlkR0s5Nd8",
    "outputId": "87381972-425f-4071-885c-7fe480ed5829"
   },
   "outputs": [],
   "source": [
    "model_10 = model_fn(keras.layers.Dropout(0.3))\n",
    "model_10.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "              metrics='accuracy')\n",
    "\n",
    "checkpoint_cb_es = keras.callbacks.ModelCheckpoint('best-model-es.h5', save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n",
    "\n",
    "history_10 = model_10.fit(train_scaled, train_target, epochs=20, verbose=1,\n",
    "                    validation_data=(val_scaled, val_target),\n",
    "                    callbacks=[checkpoint_cb_es, early_stopping_cb])\n",
    "\n",
    "# In this case,restore_best_weights does not have be set to True because checkpoint_cb is also saving the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6TazMcDxqXD",
    "outputId": "08f6e06d-5c0e-49bd-d26f-4c190ab234ee"
   },
   "outputs": [],
   "source": [
    "print(early_stopping_cb.stopped_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "QrUNYGPB6Kq7",
    "outputId": "78ccff2f-d479-4f5a-b025-39f3eb8a6077"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_10.history['loss'])\n",
    "plt.plot(history_10.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H-7y1qlg5yqO",
    "outputId": "9b47bf70-0c0f-47bd-d88e-1b9213203040"
   },
   "outputs": [],
   "source": [
    "model_10.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u68OS_2VklFH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
