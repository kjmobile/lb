{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kjmobile/lb/blob/main/8_Ensemble_Learning_Random_Forest_and_Boosting_Q.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zp6fW8MP-mrO"
   },
   "source": [
    "# Ensemble of Decision Trees\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIaIAizcRSG-"
   },
   "source": [
    "## Bagging\n",
    "A method that combines the predictions of multiple independent weak learners to form a more robust model through parallel training and averaging the results.\n",
    "\n",
    " Bootstrapping is used to train each tree on a different data sample, leading to diverse trees that, when combined, reduce variance and improve **generalization**.\n",
    "\n",
    " It also prevents overfitting by learning from only a portion of the data, while the random selection of features at each node reduces correlation between trees, resulting in **less overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcehPL-aKKsL"
   },
   "source": [
    "\n",
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ioJUlZ0M_uSZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine=pd.read_csv('https://raw.githubusercontent.com/kjmobile/data/main/ml/wine_csv.csv')\n",
    "\n",
    "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
    "target = wine['class'].to_numpy()\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JDKQudr7_8nu",
    "outputId": "83e4afa0-9ded-459d-82f1-a47928b567cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9980758013714472 0.8864707188865033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=17)\n",
    "scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1) #default 5-fold cv\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score'])) # some overfitting is shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "S8ttU2SxhdZr"
   },
   "outputs": [],
   "source": [
    "rf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "BcCkxjqASMHj",
    "outputId": "95f98a07-b661-4604-f55c-52928c0dbc6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>sugar</th>\n",
       "      <th>pH</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>11.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.27</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>9.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>9.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>12.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>11.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  sugar    pH  class\n",
       "0         9.4    1.9  3.51    0.0\n",
       "1         9.8    2.6  3.20    0.0\n",
       "2         9.8    2.3  3.26    0.0\n",
       "3         9.8    1.9  3.16    0.0\n",
       "4         9.4    1.9  3.51    0.0\n",
       "...       ...    ...   ...    ...\n",
       "6492     11.2    1.6  3.27    1.0\n",
       "6493      9.6    8.0  3.15    1.0\n",
       "6494      9.4    1.2  2.99    1.0\n",
       "6495     12.8    1.1  3.34    1.0\n",
       "6496     11.8    0.8  3.26    1.0\n",
       "\n",
       "[6497 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XYDbzXNLG8fK",
    "outputId": "7e84db43-7c74-4950-e075-bafc6ff180f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22986133 0.50020073 0.26993794]\n"
     ]
    }
   ],
   "source": [
    "rf.fit(train_input, train_target)\n",
    "print(rf.feature_importances_) #sugar is most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27eb91975f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.barh(y=range(3), width=rf.feature_importances_, label=['alchol', 'sugar','ph'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwQv-7XZ3wHR"
   },
   "outputs": [],
   "source": [
    "# What is the 'default' number of trees in random forest?\n",
    "RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usODdDHdC4O0"
   },
   "source": [
    "Random forests create bootstrapped samples by allowing duplicates from the training set to train decision trees.\n",
    "\n",
    "There are samples that do not get included in these bootstrapped samples, known as **Out-Of-Bag (OOB) samples**.\n",
    "\n",
    "These samples can be used to evaluate the trees that were trained on the bootstrapped samples, acting similarly to a validation set!\n",
    "\n",
    "Using the OOB score can replace the need for cross-validation, allowing for the use of more samples in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMc06S1Fa_A-",
    "outputId": "6fd03f0f-265c-4d8d-d0b4-8a85a3725f54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8962863190302097\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the performance using oob_score =True instead of using cv.\n",
    "# It allows using more samples for training\n",
    "rf1 = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=17)\n",
    "\n",
    "rf1.fit(train_input, train_target)\n",
    "print(rf1.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XDd03V1gNOu0",
    "outputId": "4bf6bee7-be81-410d-dde5-6f5230132469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9976909755628247\n",
      "0.9007692307692308\n"
     ]
    }
   ],
   "source": [
    "# compare the oob_score with train score and test score\n",
    "print(rf1.score(train_input, train_target))\n",
    "print(rf1.score(test_input, test_target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y13j-wz4BuwU"
   },
   "source": [
    "When making predictions for classification, the random forest aggregates the predictions of all individual trees. Each tree gives a class probability estimate, and the forest takes the average of these probabilities across all trees for each class (i.e.,soft-voting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BySw8mGIIYCq"
   },
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tly6DOZTI1bi"
   },
   "source": [
    "A method that sequentially combines multiple weak learners into a strong learner by iteratively adjusting the weights of training instances to focus on difficult cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHpPCZkCZ9hX"
   },
   "source": [
    "# Adaptive Boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8eY3TfuaJ92",
    "outputId": "c71c9529-5d7c-48f9-f627-0f964c316dd4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leek27\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.8678083977338247, Test Score: 0.859150255423114\n",
      "Feature Importances: [0.04278414 0.80740946 0.14980641]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2), n_estimators=500, learning_rate=0.1,algorithm='SAMME', random_state=17) #default n_estimator is 50\n",
    "scores = cross_validate(ada, train_input, train_target, return_train_score=True, n_jobs=-1) #default k=5\n",
    "ada.fit(train_input, train_target)\n",
    "\n",
    "print(f'Train Score: {np.mean(scores[\"train_score\"])}, Test Score: {np.mean(scores[\"test_score\"])}')\n",
    "print(f'Feature Importances: {ada.feature_importances_}')\n",
    "\n",
    "#The default base learner in AdaBoost is a DecisionTreeClassifier with max_depth=1, we used a decision stump with slightly less weak by setting it 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csKxnaxeRX8s"
   },
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "txwMkbWkqMX_"
   },
   "outputs": [],
   "source": [
    "gb?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNpeS8EWpeEi",
    "outputId": "1423cdd7-a1d5-4ac5-c016-9311c12fdd30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8865213413445311 0.8687706374472496\n",
      "[0.13611058 0.72507684 0.13881258]\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(random_state=17)\n",
    "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
    "#used the default gb model (maxdepth=3) to get the fiture_importances\n",
    "gb.fit(train_input, train_target)\n",
    "print(gb.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B-t0jc3znEpb",
    "outputId": "e19ead22-f6b4-4c10-d464-8f32870ea865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9031173274377509 0.8708871325979122\n",
      "[0.13611058 0.72507684 0.13881258]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb1 = GradientBoostingClassifier(max_depth=4, random_state=17)\n",
    "scores = cross_validate(gb1, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
    "gb.fit(train_input, train_target)\n",
    "print(gb.feature_importances_)\n",
    "# method to pass the max_depth is not the same as as adaBost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njjaop8QKQb7"
   },
   "source": [
    "<style>\n",
    ".cell {\n",
    "  font-family: \"times new roman\";\n",
    "}\n",
    "\n",
    "\n",
    "Initialize weights for each data point $i$:\n",
    "$$w_i = \\frac{1}{m} \\quad \\text{for} \\quad i = 1, 2, \\ldots, m.$$\n",
    "\n",
    "For the error $ r_j \\text{ of } h_j(x)$:\n",
    "\n",
    "$$r_j = \\frac{\\sum_{i=1}^m w_i \\cdot \\mathbf{1}_{(h_j(x_i) \\neq y_i)}}{\\sum_{i=1}^m w_i}$$\n",
    "\n",
    "\n",
    "For the predictor weight $\\alpha_j$:\n",
    "\n",
    "$$ \\alpha_j = \\eta \\log \\left( \\frac{1 - r_j}{r_j} \\right) $$\n",
    "\n",
    "\n",
    "For updating the weights for each data point $i$:\n",
    "\n",
    "$$\n",
    "w_i \\leftarrow\n",
    "\\begin{cases}\n",
    "w_i & \\text{if } h_j(x_i) = y_i, \\\\\n",
    "w_i \\exp(\\alpha_j) & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "For the final prediction for a new data point $x$:\n",
    "$$ \\hat{y}(x) = \\underset{k}{\\operatorname{argmax}} \\sum_{j=1}^N \\alpha_j \\cdot \\mathbf{1}_{(h_j(x) = k)}$$\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
